{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:46:12.049190Z",
     "start_time": "2025-07-16T05:46:12.045246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sympy.core.relational import is_eq\n",
    "\n",
    "from plotting import plot_city_tour,plot_ea_convergence\n",
    "from utils import DataType,DATA_TYPE_2_DATA_STRING,parse_tsp_data,DATA_2_OPTIMUM_TOUR,get_distance_matrix\n",
    "from utils import save_json,load_results"
   ],
   "id": "359eaa9fa415da03",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:46:12.081855Z",
     "start_time": "2025-07-16T05:46:12.079122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deap import base, creator, tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "from typing import List\n",
    "from time import perf_counter\n"
   ],
   "id": "29c528f66685b40f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:46:12.130747Z",
     "start_time": "2025-07-16T05:46:12.127574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Experiment-Parameter (angepasst für schnellere Laufzeit) ---\n",
    "# Für finale Ergebnisse können diese Werte wieder erhöht werden (z.B. NUM_RUNS=30, NUM_GENERATIONS=200)\n",
    "NUM_RUNS = 2              # Reduziert von 10 für schnellere Demonstration\n",
    "NUM_GENERATIONS = 100    # Reduziert von 200\n",
    "POP_SIZES = [50]\n",
    "TRUNCATION_PERCENTAGE = 0.2\n",
    "MUTATION_RATE = 0.2\n",
    "# Tabu-Search-Parameter\n",
    "TS_ITERATIONS = 10        # Reduziert von 15, um die teure lokale Suche zu beschleunigen\n",
    "TABU_LIST_SIZE = 20\n",
    "# Hybrid-Parameter\n",
    "\n",
    "HYBRID_TS_START_GENERATION = int(NUM_GENERATIONS * .9)\n",
    "HYBRID_TS_IMPROVE_PERCENTAGE = 0.2\n",
    "\n",
    "data_type = DataType.BERLIN52"
   ],
   "id": "a8a2092ecfdb540",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:46:12.182858Z",
     "start_time": "2025-07-16T05:46:12.175306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Daten direkt aus dem String laden\n",
    "OPTIMUM_TOUR = DATA_2_OPTIMUM_TOUR[data_type] \n",
    "DATA_STRING = DATA_TYPE_2_DATA_STRING[data_type]\n",
    "coords = parse_tsp_data(DATA_STRING)\n",
    "points = [(i, x, y) for i, (x, y) in enumerate(coords)]\n",
    "dist_matrix = get_distance_matrix(coords)\n",
    "NUM_CITIES = len(coords)\n"
   ],
   "id": "af996bf4e1e1ce90",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:46:12.251337Z",
     "start_time": "2025-07-16T05:46:12.229984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def calculate_tour_length(tour: List[int], dist_matrix: np.ndarray, fitness_tracker=None) -> float:\n",
    "    if fitness_tracker is not None:\n",
    "        fitness_tracker['count'] += 1\n",
    "    tour_array = np.array(tour)\n",
    "    from_indices = tour_array\n",
    "    to_indices = np.roll(tour_array, -1)\n",
    "    return np.sum(dist_matrix[from_indices, to_indices])\n",
    "\n",
    "def _find_neighborhood(solution, dist_matrix, fitness_tracker=None, n_opt=1):\n",
    "    neighborhood = []\n",
    "    solution_length = len(solution)\n",
    "\n",
    "    for i in range(1, solution_length - n_opt):\n",
    "        idx1 = list(range(i, i + n_opt))\n",
    "\n",
    "        for j in range(1, solution_length - n_opt):\n",
    "            idx2 = list(range(j, j + n_opt))\n",
    "\n",
    "            if set(idx1) & set(idx2):\n",
    "                continue\n",
    "\n",
    "            new_solution = solution[:]\n",
    "            for k in range(n_opt):\n",
    "                new_solution[idx1[k]], new_solution[idx2[k]] = (\n",
    "                    solution[idx2[k]],\n",
    "                    solution[idx1[k]]\n",
    "                )\n",
    "\n",
    "            total_cost = calculate_tour_length(new_solution, dist_matrix, fitness_tracker)\n",
    "            candidate = new_solution + [total_cost]\n",
    "\n",
    "            if candidate not in neighborhood:\n",
    "                neighborhood.append(candidate)\n",
    "\n",
    "    neighborhood.sort(key=lambda x: x[-1])\n",
    "    return neighborhood\n",
    "\n",
    "def tabu_search(initial_solution, initial_cost, dist_matrix, iterations, tabu_size, n_opt=1, fitness_tracker=None):\n",
    "    solution = initial_solution\n",
    "    best_solution = initial_solution\n",
    "    best_cost = initial_cost\n",
    "    tabu_list = []\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < iterations:\n",
    "        neighborhood = _find_neighborhood(solution, dist_matrix, fitness_tracker=fitness_tracker, n_opt=n_opt)\n",
    "        move_accepted = False\n",
    "        candidate_index = 0\n",
    "\n",
    "        while not move_accepted and candidate_index < len(neighborhood):\n",
    "            candidate = neighborhood[candidate_index]\n",
    "            candidate_solution = candidate[:-1]\n",
    "            candidate_cost = candidate[-1]\n",
    "\n",
    "            diff_current = []\n",
    "            diff_candidate = []\n",
    "            for a, b in zip(solution, candidate_solution):\n",
    "                if a != b:\n",
    "                    diff_current.append(a)\n",
    "                    diff_candidate.append(b)\n",
    "                if len(diff_current) == n_opt:\n",
    "                    break\n",
    "\n",
    "            move = diff_current + diff_candidate\n",
    "            reverse_move = diff_candidate + diff_current\n",
    "\n",
    "            if move not in tabu_list and reverse_move not in tabu_list:\n",
    "                tabu_list.append(move)\n",
    "                solution = candidate_solution\n",
    "                move_accepted = True\n",
    "\n",
    "                if candidate_cost < best_cost:\n",
    "                    best_cost = candidate_cost\n",
    "                    best_solution = candidate_solution\n",
    "\n",
    "            candidate_index += 1\n",
    "\n",
    "        if len(tabu_list) > tabu_size:\n",
    "            tabu_list.pop(0)\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return best_solution, best_cost\n",
    "\n",
    "def evaluation(individual: List[int], dist_matrix: np.ndarray, fitness_tracker=None):\n",
    "    return (calculate_tour_length(individual, dist_matrix, fitness_tracker),)\n",
    "\n",
    "def record_log(gen, population, log_book: List, fitness_counter: int) -> List:\n",
    "    best = tools.selBest(population, 1)[0]\n",
    "    log_book.append([\n",
    "        gen,\n",
    "        fitness_counter,\n",
    "        best.fitness.values[0],\n",
    "        np.mean([ind.fitness.values[0] for ind in population])\n",
    "    ])\n",
    "    return log_book\n",
    "\n",
    "def run_hybrid_ea(pop_size: int, num_generations: int, dist_matrix: np.ndarray):\n",
    "    fitness_tracker = {'count': 0}\n",
    "\n",
    "    if not hasattr(creator, \"FitnessMin\"):\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    if not hasattr(creator, \"Individual\"):\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"indices\", random.sample, range(NUM_CITIES), NUM_CITIES)\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    evaluate = partial(evaluation, dist_matrix=dist_matrix, fitness_tracker=fitness_tracker)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxOrdered)\n",
    "    toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selBest)\n",
    "\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    logbook = []\n",
    "\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    logbook = record_log(0, pop, logbook, fitness_counter=fitness_tracker['count'])\n",
    "    tabu_total_time = 0.0\n",
    "\n",
    "    for gen in range(1, num_generations ):\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < 0.9:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values, child2.fitness.values\n",
    "\n",
    "        for mutant in offspring:\n",
    "            if random.random() < 0.2:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        if gen >= HYBRID_TS_START_GENERATION:\n",
    "            gen_tabu_start = perf_counter()\n",
    "            offspring.sort(key=lambda ind: ind.fitness.values[0] if ind.fitness.valid else float('inf'))\n",
    "            num_to_improve = max(1, int(pop_size * HYBRID_TS_IMPROVE_PERCENTAGE))\n",
    "\n",
    "            for i in range(num_to_improve):\n",
    "                tour = offspring[i]\n",
    "                tour_indices = list(tour)\n",
    "                cost = tour.fitness.values[0] if tour.fitness.valid else calculate_tour_length(tour_indices, dist_matrix, fitness_tracker)\n",
    "\n",
    "                improved_tour, improved_cost = tabu_search(\n",
    "                    tour_indices,\n",
    "                    cost,\n",
    "                    dist_matrix,\n",
    "                    TS_ITERATIONS,\n",
    "                    TABU_LIST_SIZE,\n",
    "                    n_opt=1,\n",
    "                    fitness_tracker=fitness_tracker\n",
    "                )\n",
    "\n",
    "                if len(set(improved_tour)) != NUM_CITIES:\n",
    "                    raise ValueError(\"Some cities were lost during Tabu Search\")\n",
    "\n",
    "                offspring[i][:] = improved_tour\n",
    "                offspring[i].fitness.values = (improved_cost,)\n",
    "\n",
    "            print(f\"    [GEN {gen}] Tabu search time: {perf_counter() - gen_tabu_start:.2f} sec\")\n",
    "\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = list(map(toolbox.evaluate, invalid_ind))\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        pop[:] = offspring\n",
    "        logbook = record_log(gen, pop, logbook, fitness_counter=fitness_tracker['count'])\n",
    "\n",
    "    print(f\"  >> [Hybrid-EA] Total Tabu search time this run: {tabu_total_time:.2f} seconds\")\n",
    "\n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    return best_ind.fitness.values[0], list(best_ind), pd.DataFrame(\n",
    "        logbook,\n",
    "        columns=['Generation', 'Total_Fitness_Evaluations', 'Best_Fitness_Generation', 'Avg_Fitness_Generation']\n",
    "    )\n",
    "\n",
    "def run_pure_ea(pop_size: int, num_generations: int, dist_matrix: np.ndarray):\n",
    "    fitness_tracker = {'count': 0}\n",
    "\n",
    "    if not hasattr(creator, \"FitnessMin\"):\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    if not hasattr(creator, \"Individual\"):\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"indices\", random.sample, range(NUM_CITIES), NUM_CITIES)\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    evaluate = partial(evaluation, dist_matrix=dist_matrix, fitness_tracker=fitness_tracker)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxOrdered)\n",
    "    toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selBest)\n",
    "\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    logbook = []\n",
    "\n",
    "    # Initial fitness evaluation\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    logbook = record_log(0, pop, logbook, fitness_counter=fitness_tracker['count'])\n",
    "\n",
    "    for gen in range(1, num_generations):\n",
    "        # Selection and cloning\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        # Apply crossover\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < 0.9:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values, child2.fitness.values\n",
    "\n",
    "        # Apply mutation\n",
    "        for mutant in offspring:\n",
    "            if random.random() < 0.2:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        # Evaluate invalid individuals\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = list(map(toolbox.evaluate, invalid_ind))\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update population\n",
    "        pop[:] = offspring\n",
    "        logbook = record_log(gen, pop, logbook, fitness_counter=fitness_tracker['count'])\n",
    "\n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    return best_ind.fitness.values[0], list(best_ind), pd.DataFrame(\n",
    "        logbook,\n",
    "        columns=['Generation', 'Total_Fitness_Evaluations', 'Best_Fitness_Generation', 'Avg_Fitness_Generation']\n",
    "    )\n"
   ],
   "id": "5233a91ef3f39cbc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:46:12.278168Z",
     "start_time": "2025-07-16T05:46:12.273036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "\n",
    "class RunType(Enum):\n",
    "    EA = 'ea'    \n",
    "    HYBRID = 'hybrid'\n",
    "\n",
    "RUN_FUNC_MAP = {RunType.HYBRID:run_hybrid_ea,\n",
    "            RunType.EA:run_pure_ea} \n",
    "\n",
    "def get_proper_out_put_name(run_type:RunType,data_type:DataType,pop_size:int,n_generation:int):\n",
    "    name = f\"{data_type.value}_{run_type.name}_pop_{pop_size}_gen_{n_generation}\"\n",
    "    return name\n",
    "\n",
    "def run_multiple_configs(pop_size:int,n_runs:int,run_type:RunType):\n",
    "    all_results = {}\n",
    "    all_logs = {}\n",
    "    best_tours = {}\n",
    "\n",
    "    \n",
    "    key = f\"{run_type.name}_{pop_size}\"\n",
    "    print(f\"  -> Starting runs for: {key}\")\n",
    "\n",
    "    final_fitnesses_run = []\n",
    "    run_logs = []\n",
    "    best_tour_run = None\n",
    "    best_fitness_run = float('inf')\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        print(f\" {key}  -> Run {i+1}/{n_runs}...\", end=\"\")\n",
    "        # final_fitness, final_tour, log_data = run_hybrid_ea(pop_size, NUM_GENERATIONS, dist_matrix)\n",
    "        run_func = RUN_FUNC_MAP[run_type]\n",
    "        final_fitness, final_tour, log_data = run_func(pop_size, NUM_GENERATIONS, dist_matrix)\n",
    "        final_fitnesses_run.append(final_fitness)\n",
    "        run_logs.append(log_data)\n",
    "\n",
    "        if final_fitness < best_fitness_run:\n",
    "            best_fitness_run = final_fitness\n",
    "            best_tour_run = final_tour\n",
    "        print(\" done\")\n",
    "\n",
    "    all_results[key] = final_fitnesses_run\n",
    "    all_logs[key] = run_logs\n",
    "    best_tours[key] = best_tour_run\n",
    "    print(len(all_logs))\n",
    "    return all_results, all_logs, best_tours"
   ],
   "id": "89b9e444d8a33389",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:49:23.866741Z",
     "start_time": "2025-07-16T05:46:12.329106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "  \n",
    "'attention here only one pop size is passed for simplicity'\n",
    "\n",
    "for run_type in RunType:\n",
    "    pop_size = POP_SIZES[0]\n",
    "    all_results, all_logs, best_tours = run_multiple_configs(pop_size=pop_size,n_runs=NUM_RUNS,run_type=run_type)\n",
    "    out_put_name = get_proper_out_put_name(run_type=run_type,pop_size=pop_size,n_generation=NUM_GENERATIONS)\n",
    "    plot_ea_convergence(all_logs=all_logs,n_runs=NUM_RUNS,save_name=out_put_name)\n",
    "    plot_city_tour(all_results=all_results,best_tours=best_tours,coords=coords,data_type=data_type,save_name=out_put_name)    \n",
    "    save_json(all_results=all_results,all_logs=all_logs,best_tours=best_tours,save_name=out_put_name)\n",
    "\n",
    "    \n",
    "\n",
    "# new_all_results, new_all_logs, new_best_tours = load_results('./results.json')"
   ],
   "id": "2744b8ad0347d22d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Starting runs for: EA_50\n",
      " EA_50  -> Run 1/2... done\n",
      " EA_50  -> Run 2/2... done\n",
      "1\n",
      "\n",
      "Best tour found comes from 'EA_50' with a length of 25204.87\n",
      "  -> Starting runs for: HYBRID_50\n",
      " HYBRID_50  -> Run 1/2...    [GEN 90] Tabu search time: 9.11 sec\n",
      "    [GEN 91] Tabu search time: 9.23 sec\n",
      "    [GEN 92] Tabu search time: 9.20 sec\n",
      "    [GEN 93] Tabu search time: 8.73 sec\n",
      "    [GEN 94] Tabu search time: 9.37 sec\n",
      "    [GEN 95] Tabu search time: 9.67 sec\n",
      "    [GEN 96] Tabu search time: 9.01 sec\n",
      "    [GEN 97] Tabu search time: 9.68 sec\n",
      "    [GEN 98] Tabu search time: 9.73 sec\n",
      "    [GEN 99] Tabu search time: 9.61 sec\n",
      "  >> [Hybrid-EA] Total Tabu search time this run: 0.00 seconds\n",
      " done\n",
      " HYBRID_50  -> Run 2/2...    [GEN 90] Tabu search time: 9.50 sec\n",
      "    [GEN 91] Tabu search time: 9.00 sec\n",
      "    [GEN 92] Tabu search time: 9.62 sec\n",
      "    [GEN 93] Tabu search time: 9.39 sec\n",
      "    [GEN 94] Tabu search time: 9.10 sec\n",
      "    [GEN 95] Tabu search time: 9.21 sec\n",
      "    [GEN 96] Tabu search time: 10.18 sec\n",
      "    [GEN 97] Tabu search time: 10.46 sec\n",
      "    [GEN 98] Tabu search time: 10.54 sec\n",
      "    [GEN 99] Tabu search time: 9.43 sec\n",
      "  >> [Hybrid-EA] Total Tabu search time this run: 0.00 seconds\n",
      " done\n",
      "1\n",
      "\n",
      "Best tour found comes from 'HYBRID_50' with a length of 9523.55\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:50:22.170018Z",
     "start_time": "2025-07-16T05:50:22.167948Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9bf51d6ea09ac1a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:49:23.938072Z",
     "start_time": "2025-07-16T05:49:23.935993Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "10015b3b9f4c1e31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:49:23.983506Z",
     "start_time": "2025-07-16T05:49:23.981575Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c005dd0afb34c7b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:49:24.029656Z",
     "start_time": "2025-07-16T05:49:24.027686Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dc11c9ef1b328b2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:49:24.074967Z",
     "start_time": "2025-07-16T05:49:24.073384Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "180f4d6d325e93f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:49:24.120321Z",
     "start_time": "2025-07-16T05:49:24.118571Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6793f6bea9afca93",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
